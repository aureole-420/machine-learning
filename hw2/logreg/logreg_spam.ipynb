{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regularized logistic regression to classify email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3065, 57)\n",
      "L2 Penalty experiments -----------\n",
      "reg =  0.1\n",
      "reg =  0.6\n",
      "reg =  1.1\n",
      "reg =  1.6\n",
      "reg =  2.1\n",
      "reg =  2.6\n",
      "reg =  3.1\n",
      "reg =  3.6\n",
      "reg =  4.1\n",
      "reg =  4.6\n",
      "best_lambda =  4.1\n",
      "Coefficients =  [-1.62837284] [[-0.01839052 -0.21661119  0.13128384  0.48674888  0.2602243   0.18532733\n",
      "   0.90344911  0.31288822  0.14199547  0.06198638 -0.05335911 -0.15162932\n",
      "  -0.0516569   0.02767041  0.23856918  0.76613529  0.46856035  0.08308522\n",
      "   0.26257561  0.22073129  0.26177729  0.41125323  0.7503693   0.26021176\n",
      "  -1.80207063 -0.62172528 -1.83095331 -0.11174736 -0.67814627 -0.16857307\n",
      "  -0.29711007 -0.20770702 -0.41815432 -0.42931161 -0.34816875  0.32415601\n",
      "   0.010483   -0.14344427 -0.3803836  -0.09968338 -0.63272648 -0.95488787\n",
      "  -0.32285734 -0.7132242  -0.79373552 -1.16416329 -0.133999   -0.67460068\n",
      "  -0.33001795 -0.15734097 -0.11687446  0.22802517  1.48301759  0.49456055\n",
      "  -0.12310253  0.83739199  0.38195683]]\n",
      "Accuracy on set aside test set for  std  =  0.921875\n",
      "reg =  0.1\n",
      "reg =  0.6\n",
      "reg =  1.1\n",
      "reg =  1.6\n",
      "reg =  2.1\n",
      "reg =  2.6\n",
      "reg =  3.1\n",
      "reg =  3.6\n",
      "reg =  4.1\n",
      "reg =  4.6\n",
      "best_lambda =  0.6\n",
      "Coefficients =  [-4.60944122] [[-0.45145757 -0.28466462 -0.06326919  0.6829589   1.21053268  0.91505184\n",
      "   2.83046516  1.4367911   0.24145529  0.35776718 -0.38644427 -0.48143423\n",
      "  -0.69587018  0.37456786  0.64885559  1.53956348  1.38117816  0.07197439\n",
      "   0.3764288   0.63502239  0.52274071  0.38563885  2.00139494  1.50816963\n",
      "  -3.1406125  -0.66616118 -4.90648747 -0.0325955  -1.28886416 -0.15745769\n",
      "  -0.63900743 -0.30230496 -1.00989865 -0.42569132 -1.0872222   1.28435159\n",
      "  -0.90558562 -0.35286056 -1.12971577 -0.62591345 -1.40337387 -2.44124219\n",
      "  -1.55654176 -1.94777878 -1.13114764 -2.79991607 -0.75122172 -2.11603159\n",
      "  -1.68511673 -0.66774008 -0.6912591   2.06912383  4.21977419  0.76308593\n",
      "   0.70345787  0.17008379  0.43018826]]\n",
      "Accuracy on set aside test set for  logt  =  0.943359375\n",
      "reg =  0.1\n",
      "reg =  0.6\n",
      "reg =  1.1\n",
      "reg =  1.6\n",
      "reg =  2.1\n",
      "reg =  2.6\n",
      "reg =  3.1\n",
      "reg =  3.6\n",
      "reg =  4.1\n",
      "reg =  4.6\n",
      "best_lambda =  1.6\n",
      "Coefficients =  [-1.82566817] [[ -1.78313887e-01  -1.60085507e-01  -3.73001110e-01   2.36358803e-01\n",
      "    9.46367589e-01   1.59613651e-01   2.03690641e+00   7.62617293e-01\n",
      "    1.81159712e-01   3.12388353e-01  -2.60352275e-01  -4.14115142e-01\n",
      "   -8.66097179e-01   2.36335390e-01   4.75358416e-01   1.43030139e+00\n",
      "    8.23118667e-01  -6.18540137e-02   2.39595774e-01   4.50237962e-01\n",
      "    7.24354332e-01   1.06352180e+00   8.70212070e-01   1.30340906e+00\n",
      "   -2.20348245e+00  -4.57176450e-01  -3.39242058e+00   5.45347539e-01\n",
      "   -5.60588209e-01  -1.85244388e-01  -8.05548612e-01  -4.84223733e-01\n",
      "   -6.36751901e-01  -8.68074827e-02  -6.31860077e-01   3.04485692e-01\n",
      "   -1.03756760e+00   4.18380738e-01  -7.08628404e-01  -2.18361508e-01\n",
      "   -1.07385026e+00  -1.74862153e+00  -6.95533233e-01  -1.43004581e+00\n",
      "   -7.40200632e-01  -2.11078935e+00  -9.46977029e-02  -1.24285032e+00\n",
      "   -2.91376073e-01   1.90460650e-01  -1.65731167e-01   1.19345678e+00\n",
      "    1.42337675e+00   6.04361397e-02   7.86190274e-04   7.86190274e-04\n",
      "    7.86190274e-04]]\n",
      "Accuracy on set aside test set for  bin  =  0.928385416667\n",
      "L1 Penalty experiments -----------\n",
      "reg =  0.1\n",
      "reg =  0.6\n",
      "reg =  1.1\n",
      "reg =  1.6\n",
      "reg =  2.1\n",
      "reg =  2.6\n",
      "reg =  3.1\n",
      "reg =  3.6\n",
      "reg =  4.1\n",
      "reg =  4.6\n",
      "best_lambda =  0.6\n",
      "Coefficients =  [-6.21720372] [[ -3.35405339e-02  -2.03581703e-01   1.16590180e-01   1.33821077e+00\n",
      "    2.70663808e-01   2.40586996e-01   9.08512721e-01   2.97333323e-01\n",
      "    1.73232882e-01   6.89125659e-02  -7.38472102e-02  -1.55925080e-01\n",
      "   -3.30383543e-02   1.13346276e-02   1.67617365e-01   8.05984251e-01\n",
      "    5.04319045e-01   4.03974439e-02   2.65252863e-01   3.29013078e-01\n",
      "    2.60214765e-01   3.58339005e-01   7.05434643e-01   1.95341646e-01\n",
      "   -3.08814443e+00  -3.55890071e-01  -2.06922010e+01  -5.11784881e-02\n",
      "   -1.08483878e+00  -2.24958911e-02   0.00000000e+00   0.00000000e+00\n",
      "   -3.52949522e-01   0.00000000e+00  -4.45665079e-01   4.09266811e-01\n",
      "    3.57390957e-02  -1.48754627e-01  -4.35312158e-01  -2.70707523e-02\n",
      "   -2.08157711e+00  -1.53692548e+00  -4.07793904e-01  -9.66410317e-01\n",
      "   -8.80629514e-01  -1.69073202e+00  -1.58945212e-01  -9.63604086e-01\n",
      "   -3.38021705e-01  -1.25709467e-01  -5.56734873e-02   2.00739049e-01\n",
      "    1.67604453e+00   9.08603042e-01  -3.05406957e-01   1.81779933e+00\n",
      "    3.21362551e-01]]\n",
      "Accuracy on set aside test set for  std  =  0.930989583333\n",
      "reg =  0.1\n",
      "reg =  0.6\n",
      "reg =  1.1\n",
      "reg =  1.6\n",
      "reg =  2.1\n",
      "reg =  2.6\n",
      "reg =  3.1\n",
      "reg =  3.6\n",
      "reg =  4.1\n",
      "reg =  4.6\n",
      "best_lambda =  1.6\n",
      "Coefficients =  [-4.46368002] [[-0.34350094 -0.09556654  0.          0.12928315  1.18460148  0.69055249\n",
      "   2.9133199   1.37685264  0.          0.29507886  0.         -0.48052921\n",
      "  -0.32805903  0.1072903   0.          1.49525389  1.34896633  0.\n",
      "   0.35498304  0.19672109  0.49436471  0.34739909  1.78461648  1.32949363\n",
      "  -3.49776547 -0.26970843 -7.49479918  0.         -0.41751966  0.          0.\n",
      "   0.         -0.79149793  0.         -0.23869511  0.87189501 -0.77447768\n",
      "   0.         -0.8829671   0.         -0.30411808 -2.35522948 -0.69457831\n",
      "  -1.66141081 -1.13789223 -2.98253251  0.         -1.90119581 -1.24515907\n",
      "  -0.30361639  0.          2.01468192  5.36648654  0.          0.63722659\n",
      "   0.20154557  0.38832212]]\n",
      "Accuracy on set aside test set for  logt  =  0.944010416667\n",
      "reg =  0.1\n",
      "reg =  0.6\n",
      "reg =  1.1\n",
      "reg =  1.6\n",
      "reg =  2.1\n",
      "reg =  2.6\n",
      "reg =  3.1\n",
      "reg =  3.6\n",
      "reg =  4.1\n",
      "reg =  4.6\n",
      "best_lambda =  3.6\n",
      "Coefficients =  [-0.16596963] [[ 0.          0.         -0.19383646  0.          0.86588227  0.\n",
      "   2.02968646  0.63285575  0.02657279  0.2129648   0.         -0.42078066\n",
      "  -0.68107128  0.          0.          1.31578554  0.76599965  0.\n",
      "   0.10409534  0.12274901  0.63714037  0.72965943  0.62253158  1.18352843\n",
      "  -2.42367649 -0.1267199  -3.73173117  0.          0.          0.          0.\n",
      "   0.         -0.2880102   0.         -0.21919486  0.         -1.01554874\n",
      "   0.         -0.40502703  0.         -0.11546115 -1.6944901  -0.03891436\n",
      "  -1.10996504 -0.68726439 -2.21939166  0.         -1.02545129 -0.12499356\n",
      "   0.07402714  0.          1.15109088  1.49894856  0.         -0.89836829\n",
      "  -0.40696438 -0.19416548]]\n",
      "Accuracy on set aside test set for  bin  =  0.92578125\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import utils\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "# No modifications in this script\n",
    "# complete the functions in util.py; then run the script\n",
    "\n",
    "# load the spam data in\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = utils.load_spam_data()\n",
    "\n",
    "print Xtrain.shape\n",
    "# Preprocess the data \n",
    "\n",
    "Xtrain_std,mu,sigma = utils.std_features(Xtrain)\n",
    "Xtrain_logt = utils.log_features(Xtrain)\n",
    "Xtrain_bin = utils.bin_features(Xtrain)\n",
    "\n",
    "Xtest_std = (Xtest - mu)/sigma\n",
    "Xtest_logt = utils.log_features(Xtest)\n",
    "Xtest_bin = utils.bin_features(Xtest)\n",
    "\n",
    "\n",
    "# find good lambda by cross validation for these three sets\n",
    "\n",
    "def run_dataset(X,ytrain,Xt,ytest,type,penalty):\n",
    "\n",
    "    best_lambda = utils.select_lambda_crossval(X,ytrain,0.1,5.1,0.5,penalty)\n",
    "    print \"best_lambda = \", best_lambda\n",
    "\n",
    "    # train a classifier on best_lambda and run it\n",
    "    if penalty == \"l2\":\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='lbfgs',fit_intercept=True)\n",
    "    else:\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='liblinear',fit_intercept=True)\n",
    "    lreg.fit(X,ytrain)\n",
    "    print \"Coefficients = \", lreg.intercept_,lreg.coef_\n",
    "    predy = lreg.predict(Xt)\n",
    "    print \"Accuracy on set aside test set for \", type, \" = \", np.mean(predy==ytest)\n",
    "\n",
    "print \"L2 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l2\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l2\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l2\")\n",
    "\n",
    "print \"L1 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l1\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l1\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda =  0.3 , accuracy =  0.86101141925 best_accuracy 0.0\n",
      "lambda =  0.4 , accuracy =  0.86101141925 best_accuracy 0.86101141925\n",
      "lambda =  0.5 , accuracy =  0.860032626427 best_accuracy 0.86101141925\n",
      "lambda =  0.6 , accuracy =  0.860685154976 best_accuracy 0.86101141925\n",
      "lambda =  0.7 , accuracy =  0.859706362153 best_accuracy 0.86101141925\n",
      "lambda =  0.8 , accuracy =  0.859053833605 best_accuracy 0.86101141925\n",
      "lambda =  0.9 , accuracy =  0.859380097879 best_accuracy 0.86101141925\n",
      "lambda =  1.0 , accuracy =  0.858401305057 best_accuracy 0.86101141925\n",
      "lambda =  1.1 , accuracy =  0.859053833605 best_accuracy 0.86101141925\n",
      "lambda =  1.2 , accuracy =  0.857422512235 best_accuracy 0.86101141925\n",
      "lambda =  1.3 , accuracy =  0.857096247961 best_accuracy 0.86101141925\n",
      "lambda =  1.4 , accuracy =  0.866231647635 best_accuracy 0.86101141925\n",
      "lambda =  1.5 , accuracy =  0.865905383361 best_accuracy 0.866231647635\n",
      "lambda =  1.6 , accuracy =  0.865905383361 best_accuracy 0.866231647635\n",
      "lambda =  1.7 , accuracy =  0.865905383361 best_accuracy 0.866231647635\n",
      "lambda =  1.8 , accuracy =  0.865579119086 best_accuracy 0.866231647635\n",
      "lambda =  1.9 , accuracy =  0.864926590538 best_accuracy 0.866231647635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4000000000000004"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "def select_lambda_crossval(X,y,lambda_low,lambda_high,lambda_step,penalty):\n",
    "\n",
    "    best_lambda = lambda_low\n",
    "\n",
    "    # Your code here\n",
    "    # Implement the algorithm above.\n",
    "    num_folds = 5\n",
    "    best_accuracy = 0.0\n",
    "    kf = model_selection.KFold(n_splits = num_folds)\n",
    "    for reg in np.arange(lambda_low, lambda_high, lambda_step):\n",
    "        accuracy = 0;\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train = X[train_index]\n",
    "            y_train = y[train_index]\n",
    "            X_test = X[test_index]\n",
    "            y_test = y[test_index]\n",
    "            if (penalty == \"l2\"):\n",
    "                sk_logreg = linear_model.LogisticRegression(C=1.0/reg, solver='lbfgs',fit_intercept=False, penalty=penalty)\n",
    "            elif (penalty == \"l1\"):\n",
    "                sk_logreg = linear_model.LogisticRegression(C=1.0/reg, solver='saga',fit_intercept=True,penalty=penalty)\n",
    "            else:\n",
    "                raise ValueError(\"Incorrect penalty type! Penalty can only be l2 or l1.\")\n",
    "#             sk_logreg.fit(X_train, y_train)\n",
    "            sk_logreg.fit(X_train, y_train)\n",
    "#             print X_train.shape\n",
    "            y_pred = sk_logreg.predict(X_test)\n",
    "#             y_pred = bin_features(X_test.dot(sk_logreg.coef_[0]))\n",
    "#             print y_pred\n",
    "#             print y_test\n",
    "            cur_accuracy= float(np.sum(y_pred == y_test)) / y_test.shape[0]\n",
    "#             print \"lambda = \", reg, \", accuracy = \", cur_accuracy      \n",
    "            accuracy += cur_accuracy\n",
    "            # plot_utils.plot_decision_boundary_sklearn(X_train, y_train, sk_logreg, 'Chip Test 1', 'Chip Test 2',['y = 0','y = 1']):\n",
    "        accuracy = accuracy / num_folds\n",
    "        print \"lambda = \", reg, \", accuracy = \", accuracy, \"best_accuracy\",  best_accuracy\n",
    "        if (accuracy > best_accuracy):\n",
    "            best_accuracy = accuracy\n",
    "            best_lambda = reg\n",
    "        \n",
    "    # end your code\n",
    "\n",
    "    return best_lambda\n",
    "# print Xtrain_std[range(100)]\n",
    "# print ytrain[range(1000,3000)]\n",
    "# select_lambda_crossval(Xtrain_std[range(0, 3000)],ytrain[range(0, 3000)],0.3,2,0.1, \"l1\")\n",
    "select_lambda_crossval(Xtrain_std,ytrain,0.3,2,0.1, \"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

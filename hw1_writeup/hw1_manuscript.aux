\relax 
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1}Samplers}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Visualization of four distributions\relax }}{1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:samplers}{{1}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.2}Prove two independent Poisson random variables are also Poisson variable.}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.3}Proof question 3}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.4}Eigenvalues}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.5}Matrix multiplication}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.6}Question 6}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.7}Convex function}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {0.7.1}Triple}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {0.7.2}Two dimension}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {0.7.3}Plus}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {0.7.4}Multiply}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.8}Entropy of categorical distribution}{5}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Batch gradient descent algorithm for locally weighted linear regression\relax }}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Fitting a linear model to the data\relax }}{9}}
\newlabel{fig:linear_fit}{{2}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Convergence of Loss function against the number of iterations.\relax }}{9}}
\newlabel{fig:linear_convergence}{{3}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Fitting a linear model to the data\relax }}{10}}
\newlabel{fig:3_1_B2}{{4}{10}}
\newlabel{subsec:3_1_B3}{{5}{10}}
\newlabel{fig:converg_lr}{{5d}{11}}
\newlabel{sub@fig:converg_lr}{{d}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Convergence of gradient descent for linear regression with multiple variables using different learning rate.\relax }}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The fitted curve of the linear model.\relax }}{12}}
\newlabel{fig:3_2_A2}{{6}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Learning curve of the linear model.\relax }}{12}}
\newlabel{fig:3_2_A3}{{7}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Convergence of gradient descent for linear regression with multiple variables using different learning rate.\relax }}{13}}
\newlabel{fig:3_2_A4}{{8}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Variation in training/validation error with $\lambda $\relax }}{14}}
\newlabel{fig:3_2_A5}{{9}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Averaged learning curve for $\lambda = 1$\relax }}{15}}
\newlabel{fig:3_2_A7}{{10}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Variation in training/testing error with $\lambda $ for regularized linear model\relax }}{16}}
\newlabel{fig:4_1}{{11}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Variation in training/testing error with $\lambda $ for regularized linear model with quadratic features\relax }}{16}}
\newlabel{fig:4_2}{{12}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Variation in training/testing error with $\lambda $ for regularized linear model with quadratic features\relax }}{17}}
\newlabel{fig:4_3}{{13}{17}}
